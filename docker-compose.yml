services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zookeeper
      
  mongo-express:
    image: mongo-express
    container_name: mongo_express
    restart: always
    ports:
      - "8081:8081"
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: admin
      ME_CONFIG_MONGODB_ADMINPASSWORD: password
      ME_CONFIG_MONGODB_URL: mongodb://admin:password@mongo-trusted:27017/
      ME_CONFIG_BASICAUTH: false
    depends_on:
      - mongo-trusted

  mongo-proton:
    image: mongo:latest
    container_name: proton_mongo
    restart: always
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_DATABASE: protondb
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: password
    volumes:
      - mongo_proton_data:/data/db

  proton:
    build:
      context: ./src/protondb-community-api
    container_name: proton
    environment:
      DB_URI: mongodb://admin:password@mongo-proton:27017/protondb?authSource=admin
      PORT: "3000"
    ports:
      - "3000:3000"
    depends_on:
      - mongo-proton
    dns:
      - 8.8.8.8
      - 1.1.1.1

  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "7077:7077"
      - "8080:8080"

  spark-worker:
    image: bitnami/spark:latest
    container_name: spark-worker
    ports:
      - "4000:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    volumes:
      - ./data:/data  # Mount for reading/writing delta tables
    depends_on:
      - spark-master

  # comment-generator:
  #   build:
  #     context: ./src/Protondb/ProtondbCommentGenerator
  #   container_name: comment_generator
  #   volumes:
  #     - ./data:/data
  #   command: ["python", "ProtondbCommentGenerator.py"]
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [gpu]


  mongo-trusted:
    image: mongo:latest
    container_name: mongo_trusted
    restart: "no"
    ports:
      - "27018:27017"
    environment:
      MONGO_INITDB_DATABASE: protondb
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: password
    volumes:
      - ./data/trusted_zone/mongodb:/data/db

  influx-trusted:
    image: influxdb:2.7
    container_name: influx_trusted
    restart: always
    ports:
      - "8087:8086"
    volumes:
      - ./data/trusted_zone/influxdb:/var/lib/influxdb2
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=admin
      - DOCKER_INFLUXDB_INIT_PASSWORD=admin123
      - DOCKER_INFLUXDB_INIT_ORG=steamorg
      - DOCKER_INFLUXDB_INIT_BUCKET=steammetrics
      - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=admintoken

  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data

  airflow-init:
    image: apache/airflow:2.6.3
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: your_secret_key
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    command: >
      bash -c "airflow db init && airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin"

  airflow-webserver:
    build:
      context: ./airflow         # ðŸ‘ˆ Path to Dockerfile directory
      dockerfile: Dockerfile     # ðŸ‘ˆ Optional, defaults to 'Dockerfile'
    image: custom-airflow:latest
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__WEBSERVER__SECRET_KEY: your_secret_key
      AIRFLOW__API__AUTH_BACKEND: airflow.api.auth.backend.default  # Disable authentication
      PYTHONPATH: /opt/airflow/src
    ports:
      - "8082:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
    command: webserver

  airflow-scheduler:
    build:
      context: ./airflow         # ðŸ‘ˆ Path to Dockerfile directory
      dockerfile: Dockerfile     # ðŸ‘ˆ Optional, defaults to 'Dockerfile'
    image: custom-airflow:latest
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      PYTHONPATH: /opt/airflow/src
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
    command: scheduler


  streamlit-dashboard:
    build:
      context: ./src/Frontend
    container_name: streamlit_dashboard
    ports:
      - "8501:8501"
    restart: always

volumes:
  mongo_proton_data: {}
  postgres_data:
